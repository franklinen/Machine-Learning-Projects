{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Medical Insurance Cost Using Regression\n",
    "\n",
    "Health Insurance cost is a major economic concern for most countries and corporate organisations. To remain in business and to make profits. insurance companies want to predict the exact amount to be charged on individual clients. To do this effectively, the companies lok at the health risk inherent to each client. Most appropriately, lifestyle and pre-existing condition are used to gauge the inherent risk associated with each patient and then to correctly predict the health Insurance charges for the individual.\n",
    "This study aims to use some of these individual parameters as the independent variables, X to proedict the cost of health insurance, y(dpendent variable) for a particular individual. \n",
    "\n",
    "The data used for analysis was obtined from Kaggle. Several factors affects the overall health risk of individuals. Most of those factors have to do with individual's lifestyle and present health condition. The dataset lists some of those features determining the health risks of individuals and we want to use those factors in predicting the cost of Medical insurance for the individual.  \n",
    "\n",
    "The purpose of this resarch is to try prediction with diferent regression models on the dataset and come out with the best regression model that can correctly predict the cost of Medical Isurance using the available data. All analysis was performed with python 3 using the 'Spyder' environment.\n",
    "\n",
    "Our Target variable for the Regression studies is a numerical variable detailing the health insurance cost for each observation parameters. After necessary processing, the data is split and used for analysis. Five models were used to run the analysis and the results were compared with each other to chose the ones with the highest model scores.\n",
    "\n",
    "The analytics process and results are presented below;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MAIN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\MAIN\\\\Desktop\\\\ML\\\\ML Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MAIN\\\\Desktop\\\\ML\\\\ML Project'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df= pd.read_csv(\"insurance.csv\")\n",
    "df.describe()\n",
    "#handle missing values\n",
    "df.isnull().sum()\n",
    "df.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "#check correlation with seaborn heatmap\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(40,40))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='Greens')\n",
    "\n",
    "#define X,y\n",
    "X=df.drop(['charges'],axis=1)\n",
    "y=df.charges\n",
    "\n",
    "#Normalise the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scaled = (sc.fit_transform(X))\n",
    "features=X.columns.values\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "y_scaled = sc_y.fit_transform(y.reshape(len(y),1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix shown on the heatmap analysis shown that the most feature with a strong positive correlation with the insurance charges was the 'smoker' variable followed by the \"bmi\". Th RFE was run after that to decrease the number of variables in the X independent variable. This process increases the predictive ability of the model by increasing the Adjusted R2-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################........Linear Regression.........#########################################\n",
    "#import learning model(Linear Regression)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "classifier = LinearRegression()\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Run RFE and select best subset of X\n",
    "estimator = LinearRegression() #use regression model for regression problem\n",
    "list_r2=[]\n",
    "max_r2 = 0\n",
    "for i in range(1,len(X.iloc[0])+1):\n",
    "    selector = RFE(estimator, i, step=1)\n",
    "    selector = selector.fit(X_scaled, y_scaled)\n",
    "    adj_r2 = 1 - ((len(X)-1)/(len(X)-i-1))*(1-selector.score(X_scaled, y_scaled))\n",
    "    list_r2.append(adj_r2)# mse = \n",
    "    if max_r2 < adj_r2:\n",
    "        sel_features = selector.support_\n",
    "        max_r2 = adj_r2\n",
    "        \n",
    "X_sub = X_scaled[:,sel_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression was the first model used and the main parameters for comparison were the Mean Squared Error and the R-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#statistical summary of the model\n",
    "import statsmodels.api as sm\n",
    "X2=sm.add_constant(X_sub)  #investigate\n",
    "model=sm.OLS(y,X2)\n",
    "results=model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "#split train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sub, y_scaled, test_size=0.3, random_state=0)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "#Train our model\n",
    "model1.fit(X_train,y_train)\n",
    "#predict with the model\n",
    "y_pred = model1.predict(X_test)\n",
    "b0 =model1.intercept_\n",
    "b1 =model1.coef_\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('intercept & coefficients: \\n', model1.intercept_, model1.coef_)\n",
    "print('mean squared error (training):', mean_squared_error(y_train, model1.predict(X_train)))\n",
    "print('mean squared error (testing):', mean_squared_error(y_test, y_pred))\n",
    "print('R-squared score(training):', r2_score(y_train, model1.predict(X_train)))\n",
    "print('R-squared score(testing):', r2_score(y_test, y_pred))\n",
    "\n",
    "#Run K-Fold using R2\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "shuffle = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model1, X_sub, y_scaled, cv=shuffle)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################.......KNearestNeighbor Regression..................###################################\n",
    "#import Learning model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "Regressor = KNeighborsRegressor(n_neighbors=21, weights='distance', p=1) #by default p=2. tweak n_neighbords to check accuracy\n",
    "\n",
    "#train classifier\n",
    "Regressor.fit(X_train,y_train)\n",
    "\n",
    "#predictions for test\n",
    "y_pred = Regressor.predict(X_test)\n",
    "\n",
    "#import performance measure tools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print('R-squared score(training):', r2_score(y_train, Regressor.predict(X_train)))\n",
    "print('R-squared score(testing):',r2_score(y_test, y_pred))\n",
    "\n",
    "#split X and y into K-Folds\n",
    "#Run K-Fold using R2\n",
    "shuffle = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, X_sub, y_scaled, cv=shuffle)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################..........Random Forest..........#####################################################\n",
    "\n",
    "#import Learning Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.score(X_test,y_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print('R-squared score(training):', r2_score(y_train, model.predict(X_train)))\n",
    "print('R-squared score(testing):',r2_score(y_test, y_pred))\n",
    "\n",
    "#Run K-Fold using R2\n",
    "shuffle = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, X_sub, y_scaled, cv=shuffle)\n",
    "print(scores)\n",
    "\n",
    "#check Gridsearch for model2 = RandomForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dict= {'n_estimators':range(2,30), 'max_depth':range(1,30)}\n",
    "model = GridSearchCV(model,param_dict)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.score(X_test,y_test)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############............AdaBoost Model.............#############################################################\n",
    "\n",
    "#import learning model\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.score(X_test,y_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print('R-squared score(training):', r2_score(y_train, model.predict(X_train)))\n",
    "print('R-squared score(testing):',r2_score(y_test, y_pred))\n",
    "\n",
    "#split X and y into K-Folds\n",
    "#Run K-Fold using R2\n",
    "shuffle = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, X_sub, y_scaled, cv=shuffle)\n",
    "print(scores)\n",
    "\n",
    "#check Gridsearch for model3 = AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dict= {'n_estimators':range(2,30)}\n",
    "model = GridSearchCV(model,param_dict)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.score(X_test,y_test)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############.............SVR model...........####################################################################\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "model = SVR(kernel='rbf')\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "model.score(X_test,y_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print('R-squared score(training):', r2_score(y_train, model.predict(X_train)))\n",
    "print('R-squared score(testing):',r2_score(y_test, y_pred))\n",
    "\n",
    "#split X and y into K-Folds\n",
    "#Run K-Fold using R2\n",
    "shuffle = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, X_sub, y_scaled, cv=shuffle)\n",
    "print(scores)\n",
    "\n",
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('SVM (Training set)')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Insurance Charges')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('SVM (Test set)')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Insurance Charges')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION MODELS AND THEIR SCORES\n",
    "            MODEL\tMSE\t    R2\t    K-FOLD\n",
    "Linear Regression\t0.23\t0.79\t[ 0.79972962 0.77927394  0.65223099  0.75484223  0.71574224]\n",
    "K Nearest Neighbor\t0.17\t0.84\t[ 0.85891079  0.8514326   0.76125618  0.83682225  0.76758842]\n",
    "Random Forest\t    0.13\t0.8798\t[ 0.84467637  0.86627158  0.74810597  0.83381184  0.79090569]\n",
    "AdaBoost \t\t            0.8618\t[ 0.84355021  0.86542682  0.73502305  0.82376483  0.78491412]\n",
    "Support Vector Reg\t0.1308\t0.8798\t[ 0.89149575  0.86976228  0.78512325  0.86635013  0.78377819]\n",
    "\n",
    "The results showed a high degree of prediction scores for the different models employed in the study as shown with the R2 value.\n",
    "From the scores, The Support Vector Regression and Random Forest Classifier seem to be the best model for prediction, though the other ones gave a high degree of prediction scores too. This means that we can use the features provided to the health insurance \n",
    "cost of individuals with a high degree of certainty.\n",
    "\n",
    "The Support Vector Regression is a regression model used for continous variables. Unlike other regression models, the SVR tries to fit the error within  a certain threshold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
